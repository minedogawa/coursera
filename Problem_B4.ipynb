{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Problem_B4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM8RRLNhrVonTbS5ifw2lM0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minedogawa/coursera/blob/main/Problem_B4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVNeHfQ805ei",
        "outputId": "4adabbb7-b451-4c0f-f388-94842edd12f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "56/56 - 10s - loss: 1.6557 - accuracy: 0.2264 - val_loss: 1.6100 - val_accuracy: 0.2270 - 10s/epoch - 175ms/step\n",
            "Epoch 2/100\n",
            "56/56 - 2s - loss: 1.6008 - accuracy: 0.2382 - val_loss: 1.5582 - val_accuracy: 0.4135 - 2s/epoch - 29ms/step\n",
            "Epoch 3/100\n",
            "56/56 - 2s - loss: 1.2177 - accuracy: 0.5062 - val_loss: 0.9628 - val_accuracy: 0.6090 - 2s/epoch - 29ms/step\n",
            "Epoch 4/100\n",
            "56/56 - 2s - loss: 0.7387 - accuracy: 0.6983 - val_loss: 0.7518 - val_accuracy: 0.7483 - 2s/epoch - 28ms/step\n",
            "Epoch 5/100\n",
            "56/56 - 2s - loss: 0.4571 - accuracy: 0.8466 - val_loss: 0.5017 - val_accuracy: 0.8404 - 2s/epoch - 28ms/step\n",
            "Epoch 6/100\n",
            "56/56 - 1s - loss: 0.2501 - accuracy: 0.9253 - val_loss: 0.3824 - val_accuracy: 0.8831 - 1s/epoch - 26ms/step\n",
            "Epoch 7/100\n",
            "56/56 - 1s - loss: 0.1752 - accuracy: 0.9478 - val_loss: 0.4154 - val_accuracy: 0.8854 - 1s/epoch - 26ms/step\n",
            "Epoch 8/100\n",
            "56/56 - 2s - loss: 0.1254 - accuracy: 0.9612 - val_loss: 0.3620 - val_accuracy: 0.8921 - 2s/epoch - 29ms/step\n",
            "Epoch 9/100\n",
            "56/56 - 2s - loss: 0.0879 - accuracy: 0.9775 - val_loss: 0.3669 - val_accuracy: 0.8876 - 2s/epoch - 29ms/step\n",
            "Epoch 10/100\n",
            "56/56 - 2s - loss: 0.0604 - accuracy: 0.9848 - val_loss: 0.4753 - val_accuracy: 0.8809 - 2s/epoch - 29ms/step\n",
            "Epoch 11/100\n",
            "56/56 - 2s - loss: 0.0592 - accuracy: 0.9843 - val_loss: 0.4481 - val_accuracy: 0.8787 - 2s/epoch - 29ms/step\n",
            "Epoch 12/100\n",
            "56/56 - 2s - loss: 0.0396 - accuracy: 0.9916 - val_loss: 0.4009 - val_accuracy: 0.9011 - 2s/epoch - 27ms/step\n",
            "Epoch 13/100\n",
            "56/56 - 1s - loss: 0.0314 - accuracy: 0.9921 - val_loss: 0.4519 - val_accuracy: 0.8899 - 1s/epoch - 26ms/step\n",
            "Epoch 14/100\n",
            "56/56 - 2s - loss: 0.0239 - accuracy: 0.9966 - val_loss: 0.4159 - val_accuracy: 0.9056 - 2s/epoch - 27ms/step\n",
            "Epoch 15/100\n",
            "56/56 - 1s - loss: 0.0293 - accuracy: 0.9938 - val_loss: 0.4229 - val_accuracy: 0.9056 - 1s/epoch - 27ms/step\n",
            "Epoch 16/100\n",
            "56/56 - 2s - loss: 0.0357 - accuracy: 0.9910 - val_loss: 0.5191 - val_accuracy: 0.8944 - 2s/epoch - 29ms/step\n",
            "Epoch 17/100\n",
            "56/56 - 1s - loss: 0.0269 - accuracy: 0.9944 - val_loss: 0.3910 - val_accuracy: 0.9101 - 1s/epoch - 26ms/step\n",
            "Epoch 18/100\n",
            "56/56 - 1s - loss: 0.0170 - accuracy: 0.9972 - val_loss: 0.5364 - val_accuracy: 0.8854 - 1s/epoch - 26ms/step\n",
            "Epoch 19/100\n",
            "56/56 - 2s - loss: 0.0464 - accuracy: 0.9876 - val_loss: 0.4463 - val_accuracy: 0.9079 - 2s/epoch - 28ms/step\n",
            "Epoch 20/100\n",
            "56/56 - 2s - loss: 0.0160 - accuracy: 0.9978 - val_loss: 0.5475 - val_accuracy: 0.8854 - 2s/epoch - 28ms/step\n",
            "Epoch 21/100\n",
            "56/56 - 2s - loss: 0.0390 - accuracy: 0.9893 - val_loss: 0.4422 - val_accuracy: 0.9079 - 2s/epoch - 27ms/step\n",
            "Epoch 22/100\n",
            "56/56 - 1s - loss: 0.0271 - accuracy: 0.9949 - val_loss: 0.4309 - val_accuracy: 0.8921 - 1s/epoch - 26ms/step\n",
            "Epoch 23/100\n",
            "56/56 - 1s - loss: 0.0244 - accuracy: 0.9944 - val_loss: 0.4962 - val_accuracy: 0.8921 - 1s/epoch - 27ms/step\n",
            "Epoch 24/100\n",
            "56/56 - 2s - loss: 0.0149 - accuracy: 0.9978 - val_loss: 0.4518 - val_accuracy: 0.8989 - 2s/epoch - 29ms/step\n",
            "Epoch 25/100\n",
            "56/56 - 2s - loss: 0.0100 - accuracy: 0.9989 - val_loss: 0.5119 - val_accuracy: 0.8966 - 2s/epoch - 30ms/step\n",
            "Epoch 26/100\n",
            "56/56 - 2s - loss: 0.0178 - accuracy: 0.9972 - val_loss: 0.4339 - val_accuracy: 0.9056 - 2s/epoch - 29ms/step\n",
            "Epoch 27/100\n",
            "56/56 - 2s - loss: 0.0264 - accuracy: 0.9933 - val_loss: 0.4429 - val_accuracy: 0.9011 - 2s/epoch - 29ms/step\n",
            "Epoch 28/100\n",
            "56/56 - 2s - loss: 0.0294 - accuracy: 0.9933 - val_loss: 0.6176 - val_accuracy: 0.8742 - 2s/epoch - 29ms/step\n",
            "Epoch 29/100\n",
            "56/56 - 2s - loss: 0.0434 - accuracy: 0.9882 - val_loss: 0.3431 - val_accuracy: 0.9079 - 2s/epoch - 29ms/step\n",
            "Epoch 30/100\n",
            "56/56 - 2s - loss: 0.0426 - accuracy: 0.9916 - val_loss: 0.3893 - val_accuracy: 0.9079 - 2s/epoch - 28ms/step\n",
            "Epoch 31/100\n",
            "56/56 - 1s - loss: 0.0107 - accuracy: 0.9989 - val_loss: 0.3944 - val_accuracy: 0.9101 - 1s/epoch - 26ms/step\n",
            "Epoch 32/100\n",
            "56/56 - 1s - loss: 0.0273 - accuracy: 0.9933 - val_loss: 0.4843 - val_accuracy: 0.8876 - 1s/epoch - 27ms/step\n",
            "Epoch 33/100\n",
            "56/56 - 2s - loss: 0.0243 - accuracy: 0.9933 - val_loss: 0.3136 - val_accuracy: 0.9281 - 2s/epoch - 29ms/step\n",
            "Epoch 34/100\n",
            "56/56 - 2s - loss: 0.0256 - accuracy: 0.9916 - val_loss: 0.4687 - val_accuracy: 0.8831 - 2s/epoch - 29ms/step\n",
            "Epoch 35/100\n",
            "56/56 - 2s - loss: 0.0264 - accuracy: 0.9938 - val_loss: 0.5288 - val_accuracy: 0.8966 - 2s/epoch - 29ms/step\n",
            "Epoch 36/100\n",
            "56/56 - 2s - loss: 0.0199 - accuracy: 0.9949 - val_loss: 0.3720 - val_accuracy: 0.9146 - 2s/epoch - 28ms/step\n",
            "Epoch 37/100\n",
            "56/56 - 2s - loss: 0.0119 - accuracy: 0.9983 - val_loss: 0.4145 - val_accuracy: 0.9124 - 2s/epoch - 29ms/step\n",
            "Epoch 38/100\n",
            "56/56 - 2s - loss: 0.0078 - accuracy: 0.9989 - val_loss: 0.3840 - val_accuracy: 0.9258 - 2s/epoch - 28ms/step\n",
            "Epoch 39/100\n",
            "56/56 - 2s - loss: 0.0110 - accuracy: 0.9972 - val_loss: 0.3389 - val_accuracy: 0.9303 - 2s/epoch - 29ms/step\n",
            "Epoch 40/100\n",
            "56/56 - 1s - loss: 0.0048 - accuracy: 0.9994 - val_loss: 0.3759 - val_accuracy: 0.9303 - 1s/epoch - 26ms/step\n",
            "Epoch 41/100\n",
            "56/56 - 1s - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.3973 - val_accuracy: 0.9258 - 1s/epoch - 27ms/step\n",
            "Epoch 42/100\n",
            "56/56 - 1s - loss: 0.0025 - accuracy: 0.9989 - val_loss: 0.3956 - val_accuracy: 0.9303 - 1s/epoch - 26ms/step\n",
            "Epoch 43/100\n",
            "56/56 - 2s - loss: 0.0193 - accuracy: 0.9933 - val_loss: 0.4073 - val_accuracy: 0.9258 - 2s/epoch - 29ms/step\n",
            "Epoch 44/100\n",
            "56/56 - 2s - loss: 0.0141 - accuracy: 0.9944 - val_loss: 0.3711 - val_accuracy: 0.9191 - 2s/epoch - 29ms/step\n",
            "Epoch 45/100\n",
            "56/56 - 2s - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.3563 - val_accuracy: 0.9303 - 2s/epoch - 29ms/step\n",
            "Epoch 46/100\n",
            "56/56 - 2s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3992 - val_accuracy: 0.9281 - 2s/epoch - 29ms/step\n",
            "Epoch 47/100\n",
            "56/56 - 1s - loss: 7.1081e-04 - accuracy: 1.0000 - val_loss: 0.4201 - val_accuracy: 0.9281 - 1s/epoch - 26ms/step\n",
            "Epoch 48/100\n",
            "56/56 - 2s - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.3768 - val_accuracy: 0.9213 - 2s/epoch - 28ms/step\n",
            "Epoch 49/100\n",
            "56/56 - 1s - loss: 7.5572e-04 - accuracy: 1.0000 - val_loss: 0.3841 - val_accuracy: 0.9236 - 1s/epoch - 26ms/step\n",
            "Epoch 50/100\n",
            "56/56 - 2s - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.4090 - val_accuracy: 0.9213 - 2s/epoch - 28ms/step\n",
            "Epoch 51/100\n",
            "56/56 - 2s - loss: 0.0057 - accuracy: 0.9989 - val_loss: 0.4013 - val_accuracy: 0.9213 - 2s/epoch - 29ms/step\n",
            "Epoch 52/100\n",
            "56/56 - 2s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4407 - val_accuracy: 0.9213 - 2s/epoch - 29ms/step\n",
            "Epoch 53/100\n",
            "56/56 - 2s - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.5140 - val_accuracy: 0.8966 - 2s/epoch - 29ms/step\n",
            "Epoch 54/100\n",
            "56/56 - 2s - loss: 0.0106 - accuracy: 0.9972 - val_loss: 0.4094 - val_accuracy: 0.9169 - 2s/epoch - 29ms/step\n",
            "Epoch 55/100\n",
            "56/56 - 2s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4132 - val_accuracy: 0.9236 - 2s/epoch - 28ms/step\n",
            "Epoch 56/100\n",
            "56/56 - 2s - loss: 5.8929e-04 - accuracy: 1.0000 - val_loss: 0.4356 - val_accuracy: 0.9169 - 2s/epoch - 27ms/step\n",
            "Epoch 57/100\n",
            "56/56 - 2s - loss: 4.5313e-04 - accuracy: 1.0000 - val_loss: 0.4492 - val_accuracy: 0.9169 - 2s/epoch - 29ms/step\n",
            "Epoch 58/100\n",
            "56/56 - 2s - loss: 4.7538e-04 - accuracy: 1.0000 - val_loss: 0.4527 - val_accuracy: 0.9169 - 2s/epoch - 35ms/step\n",
            "Epoch 59/100\n",
            "56/56 - 1s - loss: 3.3241e-04 - accuracy: 1.0000 - val_loss: 0.4614 - val_accuracy: 0.9169 - 1s/epoch - 27ms/step\n",
            "Epoch 60/100\n",
            "56/56 - 2s - loss: 3.4010e-04 - accuracy: 1.0000 - val_loss: 0.4765 - val_accuracy: 0.9146 - 2s/epoch - 27ms/step\n",
            "Epoch 61/100\n",
            "56/56 - 1s - loss: 0.0106 - accuracy: 0.9955 - val_loss: 0.4620 - val_accuracy: 0.9124 - 1s/epoch - 26ms/step\n",
            "Epoch 62/100\n",
            "56/56 - 2s - loss: 0.0025 - accuracy: 0.9989 - val_loss: 0.5212 - val_accuracy: 0.9169 - 2s/epoch - 28ms/step\n",
            "Epoch 63/100\n",
            "56/56 - 2s - loss: 5.5719e-04 - accuracy: 1.0000 - val_loss: 0.4743 - val_accuracy: 0.9124 - 2s/epoch - 27ms/step\n",
            "Epoch 64/100\n",
            "56/56 - 1s - loss: 3.3824e-04 - accuracy: 1.0000 - val_loss: 0.4803 - val_accuracy: 0.9191 - 1s/epoch - 26ms/step\n",
            "Epoch 65/100\n",
            "56/56 - 1s - loss: 0.0127 - accuracy: 0.9966 - val_loss: 0.3781 - val_accuracy: 0.9213 - 1s/epoch - 26ms/step\n",
            "Epoch 66/100\n",
            "56/56 - 1s - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.4955 - val_accuracy: 0.9079 - 1s/epoch - 26ms/step\n",
            "Epoch 67/100\n",
            "56/56 - 2s - loss: 0.0110 - accuracy: 0.9966 - val_loss: 0.4292 - val_accuracy: 0.9213 - 2s/epoch - 27ms/step\n",
            "Epoch 68/100\n",
            "56/56 - 2s - loss: 0.0086 - accuracy: 0.9966 - val_loss: 0.4208 - val_accuracy: 0.9146 - 2s/epoch - 27ms/step\n",
            "Epoch 69/100\n",
            "56/56 - 2s - loss: 0.0183 - accuracy: 0.9961 - val_loss: 0.4021 - val_accuracy: 0.9101 - 2s/epoch - 34ms/step\n",
            "Epoch 70/100\n",
            "56/56 - 2s - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.4783 - val_accuracy: 0.9169 - 2s/epoch - 31ms/step\n",
            "Epoch 71/100\n",
            "56/56 - 1s - loss: 0.0107 - accuracy: 0.9972 - val_loss: 0.5474 - val_accuracy: 0.9079 - 1s/epoch - 26ms/step\n",
            "Epoch 72/100\n",
            "56/56 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4198 - val_accuracy: 0.9191 - 2s/epoch - 28ms/step\n",
            "Epoch 73/100\n",
            "56/56 - 2s - loss: 4.0217e-04 - accuracy: 1.0000 - val_loss: 0.4463 - val_accuracy: 0.9169 - 2s/epoch - 30ms/step\n",
            "Epoch 74/100\n",
            "56/56 - 2s - loss: 3.5600e-04 - accuracy: 1.0000 - val_loss: 0.4413 - val_accuracy: 0.9213 - 2s/epoch - 29ms/step\n",
            "Epoch 75/100\n",
            "56/56 - 1s - loss: 2.8253e-04 - accuracy: 1.0000 - val_loss: 0.4308 - val_accuracy: 0.9213 - 1s/epoch - 27ms/step\n",
            "Epoch 76/100\n",
            "56/56 - 2s - loss: 2.4318e-04 - accuracy: 1.0000 - val_loss: 0.4408 - val_accuracy: 0.9213 - 2s/epoch - 27ms/step\n",
            "Epoch 77/100\n",
            "56/56 - 2s - loss: 2.1360e-04 - accuracy: 1.0000 - val_loss: 0.4443 - val_accuracy: 0.9213 - 2s/epoch - 28ms/step\n",
            "Epoch 78/100\n",
            "56/56 - 1s - loss: 1.9947e-04 - accuracy: 1.0000 - val_loss: 0.4537 - val_accuracy: 0.9213 - 1s/epoch - 26ms/step\n",
            "Epoch 79/100\n",
            "56/56 - 2s - loss: 2.7165e-04 - accuracy: 1.0000 - val_loss: 0.4317 - val_accuracy: 0.9236 - 2s/epoch - 27ms/step\n",
            "Epoch 80/100\n",
            "56/56 - 2s - loss: 3.7012e-04 - accuracy: 1.0000 - val_loss: 0.4771 - val_accuracy: 0.9213 - 2s/epoch - 28ms/step\n",
            "Epoch 81/100\n",
            "56/56 - 2s - loss: 1.6319e-04 - accuracy: 1.0000 - val_loss: 0.4828 - val_accuracy: 0.9213 - 2s/epoch - 42ms/step\n",
            "Epoch 82/100\n",
            "56/56 - 2s - loss: 1.5821e-04 - accuracy: 1.0000 - val_loss: 0.4896 - val_accuracy: 0.9213 - 2s/epoch - 31ms/step\n",
            "Epoch 83/100\n",
            "56/56 - 2s - loss: 1.6672e-04 - accuracy: 1.0000 - val_loss: 0.4988 - val_accuracy: 0.9191 - 2s/epoch - 29ms/step\n",
            "Epoch 84/100\n",
            "56/56 - 1s - loss: 1.3716e-04 - accuracy: 1.0000 - val_loss: 0.5019 - val_accuracy: 0.9191 - 1s/epoch - 27ms/step\n",
            "Epoch 85/100\n",
            "56/56 - 1s - loss: 1.3182e-04 - accuracy: 1.0000 - val_loss: 0.5047 - val_accuracy: 0.9191 - 1s/epoch - 26ms/step\n",
            "Epoch 86/100\n",
            "56/56 - 2s - loss: 1.2769e-04 - accuracy: 1.0000 - val_loss: 0.5023 - val_accuracy: 0.9191 - 2s/epoch - 27ms/step\n",
            "Epoch 87/100\n",
            "56/56 - 2s - loss: 1.2760e-04 - accuracy: 1.0000 - val_loss: 0.5021 - val_accuracy: 0.9191 - 2s/epoch - 28ms/step\n",
            "Epoch 88/100\n",
            "56/56 - 2s - loss: 1.1282e-04 - accuracy: 1.0000 - val_loss: 0.5065 - val_accuracy: 0.9191 - 2s/epoch - 29ms/step\n",
            "Epoch 89/100\n",
            "56/56 - 2s - loss: 1.1362e-04 - accuracy: 1.0000 - val_loss: 0.4947 - val_accuracy: 0.9169 - 2s/epoch - 28ms/step\n",
            "Epoch 90/100\n",
            "56/56 - 2s - loss: 9.5547e-05 - accuracy: 1.0000 - val_loss: 0.4968 - val_accuracy: 0.9191 - 2s/epoch - 35ms/step\n",
            "Epoch 91/100\n",
            "56/56 - 3s - loss: 1.0143e-04 - accuracy: 1.0000 - val_loss: 0.4962 - val_accuracy: 0.9191 - 3s/epoch - 51ms/step\n",
            "Epoch 92/100\n",
            "56/56 - 2s - loss: 9.6618e-05 - accuracy: 1.0000 - val_loss: 0.5095 - val_accuracy: 0.9169 - 2s/epoch - 28ms/step\n",
            "Epoch 93/100\n",
            "56/56 - 1s - loss: 8.6573e-05 - accuracy: 1.0000 - val_loss: 0.5158 - val_accuracy: 0.9169 - 1s/epoch - 26ms/step\n",
            "Epoch 94/100\n",
            "56/56 - 2s - loss: 8.1195e-05 - accuracy: 1.0000 - val_loss: 0.5189 - val_accuracy: 0.9169 - 2s/epoch - 29ms/step\n",
            "Epoch 95/100\n",
            "56/56 - 2s - loss: 8.2720e-05 - accuracy: 1.0000 - val_loss: 0.5209 - val_accuracy: 0.9169 - 2s/epoch - 29ms/step\n",
            "Epoch 96/100\n",
            "56/56 - 1s - loss: 7.4455e-05 - accuracy: 1.0000 - val_loss: 0.5236 - val_accuracy: 0.9169 - 1s/epoch - 27ms/step\n",
            "Epoch 97/100\n",
            "56/56 - 2s - loss: 7.5896e-05 - accuracy: 1.0000 - val_loss: 0.5264 - val_accuracy: 0.9169 - 2s/epoch - 28ms/step\n",
            "Epoch 98/100\n",
            "56/56 - 1s - loss: 1.7489e-04 - accuracy: 1.0000 - val_loss: 0.6740 - val_accuracy: 0.9011 - 1s/epoch - 27ms/step\n",
            "Epoch 99/100\n",
            "56/56 - 2s - loss: 0.0098 - accuracy: 0.9989 - val_loss: 0.5291 - val_accuracy: 0.9101 - 2s/epoch - 27ms/step\n",
            "Epoch 100/100\n",
            "56/56 - 2s - loss: 0.0149 - accuracy: 0.9972 - val_loss: 0.4952 - val_accuracy: 0.8966 - 2s/epoch - 27ms/step\n"
          ]
        }
      ],
      "source": [
        "# ===================================================================================================\n",
        "# PROBLEM B4\n",
        "#\n",
        "# Build and train a classifier for the BBC-text dataset.\n",
        "# This is a multiclass classification problem.\n",
        "# Do not use lambda layers in your model.\n",
        "#\n",
        "# The dataset used in this problem is originally published in: http://mlg.ucd.ie/datasets/bbc.html.\n",
        "#\n",
        "# Desired accuracy and validation_accuracy > 91%\n",
        "# ===================================================================================================\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def solution_B4():\n",
        "    bbc = pd.read_csv(\n",
        "        'https://github.com/dicodingacademy/assets/raw/main/Simulation/machine_learning/bbc-text.csv')\n",
        "\n",
        "    # DO NOT CHANGE THIS CODE\n",
        "    # Make sure you used all of these parameters or you can not pass this test\n",
        "    vocab_size = 1000\n",
        "    embedding_dim = 16\n",
        "    max_length = 120\n",
        "    trunc_type = 'post'\n",
        "    padding_type = 'post'\n",
        "    oov_tok = \"<OOV>\"\n",
        "    training_portion = .8\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "    # Using \"shuffle=False\"\n",
        "    labels = bbc[\"category\"].values.tolist()\n",
        "    sentences = bbc[\"text\"].values.tolist()\n",
        "\n",
        "    training_size = int(len(sentences) * training_portion)\n",
        "    training_sentences = sentences[:training_size]\n",
        "    training_labels = labels[:training_size]\n",
        "    validation_sentences = sentences[training_size:]\n",
        "    validation_labels = labels[training_size:]\n",
        "\n",
        "    # Fit your tokenizer with training data\n",
        "    tokenizer =  Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
        "    tokenizer.fit_on_texts(sentences)\n",
        "    word_index = tokenizer.word_index\n",
        "\n",
        "    training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "    training_padded_sequences = pad_sequences(training_sequences, padding=padding_type, maxlen=max_length, truncating=trunc_type)\n",
        "    validation_sequences = tokenizer.texts_to_sequences(validation_sentences)\n",
        "    validation_padded_sequences = pad_sequences(validation_sequences, padding=padding_type, maxlen=max_length, truncating=trunc_type)\n",
        "\n",
        "    label_tokenizer = Tokenizer()\n",
        "    label_tokenizer.fit_on_texts(labels)\n",
        "    label_word_index = label_tokenizer.word_index\n",
        "    training_label_sequences = label_tokenizer.texts_to_sequences(training_labels)\n",
        "    training_label_sequences = np.array(training_label_sequences)\n",
        "    validation_label_sequences = label_tokenizer.texts_to_sequences(validation_labels)\n",
        "    validation_label_sequences = np.array(validation_label_sequences)\n",
        "\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Conv1D(64, 5, activation='relu'),\n",
        "        tf.keras.layers.MaxPooling1D(pool_size=4),\n",
        "        tf.keras.layers.LSTM(64),\n",
        "        tf.keras.layers.Dense(6, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "    model.fit(\n",
        "        training_padded_sequences,\n",
        "        training_label_sequences,\n",
        "        epochs=100,\n",
        "        validation_data=(\n",
        "            validation_padded_sequences,\n",
        "            validation_label_sequences),\n",
        "        verbose=2)\n",
        "\n",
        "    return model\n",
        "\n",
        "    # The code below is to save your model as a .h5 file.\n",
        "    # It will be saved automatically in your Submission folder.\n",
        "if __name__ == '__main__':\n",
        "    # DO NOT CHANGE THIS CODE\n",
        "    model = solution_B4()\n",
        "    model.save(\"model_B4.h5\")"
      ]
    }
  ]
}