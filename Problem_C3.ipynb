{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Problem_C3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPgquvDenIDpIAUb5JfSie4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minedogawa/coursera/blob/main/Problem_C3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B__lB5g36xFD",
        "outputId": "10d08bbc-100f-417b-b4fe-8563a886e1e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1600 images belonging to 2 classes.\n",
            "Found 0 images belonging to 2 classes.\n",
            "Epoch 1/20\n",
            "80/80 - 49s - loss: 0.8585 - accuracy: 0.5356 - 49s/epoch - 608ms/step\n",
            "Epoch 2/20\n",
            "80/80 - 47s - loss: 0.6899 - accuracy: 0.6000 - 47s/epoch - 582ms/step\n",
            "Epoch 3/20\n",
            "80/80 - 48s - loss: 0.6536 - accuracy: 0.6369 - 48s/epoch - 594ms/step\n",
            "Epoch 4/20\n",
            "80/80 - 47s - loss: 0.6264 - accuracy: 0.6469 - 47s/epoch - 584ms/step\n",
            "Epoch 5/20\n",
            "80/80 - 47s - loss: 0.6042 - accuracy: 0.6812 - 47s/epoch - 582ms/step\n",
            "Epoch 6/20\n",
            "80/80 - 48s - loss: 0.6016 - accuracy: 0.6856 - 48s/epoch - 596ms/step\n",
            "Epoch 7/20\n",
            "80/80 - 46s - loss: 0.5770 - accuracy: 0.7094 - 46s/epoch - 578ms/step\n",
            "Epoch 8/20\n",
            "80/80 - 46s - loss: 0.5418 - accuracy: 0.7425 - 46s/epoch - 580ms/step\n",
            "Epoch 9/20\n",
            "80/80 - 48s - loss: 0.5340 - accuracy: 0.7319 - 48s/epoch - 595ms/step\n",
            "Epoch 10/20\n",
            "80/80 - 46s - loss: 0.5538 - accuracy: 0.7331 - 46s/epoch - 576ms/step\n",
            "Epoch 11/20\n",
            "80/80 - 47s - loss: 0.5036 - accuracy: 0.7631 - 47s/epoch - 590ms/step\n",
            "Epoch 12/20\n",
            "80/80 - 46s - loss: 0.4958 - accuracy: 0.7581 - 46s/epoch - 576ms/step\n",
            "Epoch 13/20\n",
            "80/80 - 46s - loss: 0.5004 - accuracy: 0.7669 - 46s/epoch - 576ms/step\n",
            "Epoch 14/20\n",
            "80/80 - 46s - loss: 0.4710 - accuracy: 0.7862 - 46s/epoch - 574ms/step\n",
            "Epoch 15/20\n",
            "80/80 - 46s - loss: 0.4588 - accuracy: 0.7881 - 46s/epoch - 574ms/step\n",
            "Epoch 16/20\n",
            "80/80 - 46s - loss: 0.4638 - accuracy: 0.7844 - 46s/epoch - 574ms/step\n",
            "Epoch 17/20\n",
            "80/80 - 46s - loss: 0.4551 - accuracy: 0.7962 - 46s/epoch - 576ms/step\n",
            "Epoch 18/20\n",
            "80/80 - 47s - loss: 0.4602 - accuracy: 0.7987 - 47s/epoch - 588ms/step\n",
            "Epoch 19/20\n",
            "80/80 - 46s - loss: 0.4336 - accuracy: 0.8019 - 46s/epoch - 573ms/step\n",
            "Epoch 20/20\n",
            "80/80 - 46s - loss: 0.4252 - accuracy: 0.8106 - 46s/epoch - 575ms/step\n"
          ]
        }
      ],
      "source": [
        "# =======================================================================================================\n",
        "# PROBLEM C3\n",
        "#\n",
        "# Build a CNN based classifier for Cats vs Dogs dataset.\n",
        "# Your input layer should accept 150x150 with 3 bytes color as the input shape.\n",
        "# This is unlabeled data, use ImageDataGenerator to automatically label it.\n",
        "# Don't use lambda layers in your model.\n",
        "#\n",
        "# The dataset used in this problem is originally published in https://www.kaggle.com/c/dogs-vs-cats/data\n",
        "#\n",
        "# Desired accuracy and validation_accuracy > 72%\n",
        "# ========================================================================================================\n",
        "\n",
        "import tensorflow as tf\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "def solution_C3():\n",
        "    data_url = 'https://github.com/dicodingacademy/assets/raw/main/Simulation/machine_learning/cats_and_dogs.zip'\n",
        "    urllib.request.urlretrieve(data_url, 'cats_and_dogs.zip')\n",
        "    local_file = 'cats_and_dogs.zip'\n",
        "    zip_ref = zipfile.ZipFile(local_file, 'r')\n",
        "    zip_ref.extractall('data/')\n",
        "    zip_ref.close()\n",
        "\n",
        "    BASE_DIR = '/content/data/cats_and_dogs_filtered'\n",
        "    train_dir = os.path.join(BASE_DIR, 'train')\n",
        "    validation_dir = os.path.join(BASE_DIR, 'validation')\n",
        "\n",
        "    train_datagen =  ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        horizontal_flip=True,\n",
        "        zoom_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        rotation_range=20,\n",
        "        validation_split=0.2)\n",
        "\n",
        "    # YOUR IMAGE SIZE SHOULD BE 150x150\n",
        "    # Make sure you used \"categorical\"\n",
        "    train_generator =  train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(150,150),\n",
        "        batch_size=20,\n",
        "        color_mode='rgb',\n",
        "        class_mode='binary',\n",
        "        subset='training')\n",
        "\n",
        "    validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    validation_generator =  validation_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(150,150),\n",
        "        batch_size=20,\n",
        "        color_mode='rgb',\n",
        "        class_mode='binary',\n",
        "        subset='validation')\n",
        "\n",
        "    model = tf.keras.models.Sequential([\n",
        "        # YOUR CODE HERE, end with a Neuron Dense, activated by 'sigmoid'\n",
        "        tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2,2),\n",
        "        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2,2),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(512, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(loss = 'binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "    model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=80,\n",
        "        epochs=20,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=20,\n",
        "        verbose=2)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# The code below is to save your model as a .h5 file.\n",
        "# It will be saved automatically in your Submission folder.\n",
        "if __name__ == '__main__':\n",
        "    # DO NOT CHANGE THIS CODE\n",
        "    model = solution_C3()\n",
        "    model.save(\"model_C3.h5\")"
      ]
    }
  ]
}